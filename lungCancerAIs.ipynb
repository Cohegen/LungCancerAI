{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcJQxMmXHjiVs5OLtp15yb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WVMxAZzpC-P0"
      },
      "outputs": [],
      "source": [
        "##import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import copy\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import ssl\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## extracting contents of Data.zip\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'Data.zip'\n",
        "\n",
        "#destination of extracted files\n",
        "extracts = \"Data\"\n",
        "\n",
        "os.makedirs(extracts,exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path,'r') as zip_ref:\n",
        "  zip_ref.extractall(extracts)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xrw6571pE3gD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"Sets/Data\"\n",
        "\n",
        "# List everything in the folder\n",
        "contents = os.listdir(folder_path)\n",
        "\n",
        "print(\"Contents of folder:\")\n",
        "for item in contents:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ZBIDN3ID_1",
        "outputId": "150bc39e-77ba-4886-f625-154844db7dbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of folder:\n",
            "valid\n",
            "test\n",
            "train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## data transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
        "    ])\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.228,0.224,0.225])\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.228,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "jzvDqTXwIoim"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##defining the model class\n",
        "class ResNetLungCancer(nn.Module):\n",
        "  def __init__(self,num_classes,use_pretrained=True):\n",
        "    super(ResNetLungCancer,self).__init__()\n",
        "    if use_pretrained:\n",
        "      weights = ResNet50_Weights.IMAGENET1K_V1\n",
        "    else:\n",
        "      weights = None\n",
        "    self.resnet = resnet50(weights=weights)\n",
        "    num_ftrs = self.resnet.fc.in_features\n",
        "    self.resnet.fc = nn.Identity()\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256,num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.resnet(x)\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "U3T4hf0Rt1u5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=50, device='cuda'):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = valid_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'valid':\n",
        "                scheduler.step(epoch_acc)\n",
        "                current_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f'Learning rate: {current_lr}')\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "3FbjHX_vuH7g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval the model\n",
        "def evaluate_model(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "    print(f'Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "EDJ43qosuO1-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKXwwkkRy1_V",
        "outputId": "4ed6f027-ed19-4434-9760-e2f1eee73ead"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/18.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/18.2 MB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m13.3/18.2 MB\u001b[0m \u001b[31m211.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m249.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m249.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  #data\n",
        "  data_dir = \"Sets/Data\"\n",
        "\n",
        "\n",
        "  train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
        "  valid_dataset = datasets.ImageFolder(os.path.join(data_dir, 'valid'), transform=valid_transforms)\n",
        "  test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
        "\n",
        "  batch_size=32\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "  valid_loader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
        "  test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
        "\n",
        "  print(f\"Number of training images: {len(train_dataset)}\")\n",
        "  print(f\"Number of validation images: {len(valid_dataset)}\")\n",
        "  print(f\"Number of testing images: {len(test_dataset)}\")\n",
        "\n",
        "  #intializing model,loss and optimizer\n",
        "  num_classes = len(train_dataset.classes)\n",
        "  model = ResNetLungCancer(num_classes)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  pretrained_params = list(model.resnet.parameters())\n",
        "  new_params  = list(model.fc.parameters())\n",
        "\n",
        "  optimizer = optim.Adam([\n",
        "       {'params':pretrained_params,'lr':1e-5},\n",
        "      {'params':new_params,'lr':1e-4}\n",
        "         ],weight_decay=1e-6)\n",
        "\n",
        "  scheduler = ReduceLROnPlateau(optimizer,patience=7,mode='max',factor=0.5)\n",
        "\n",
        "  # train the model\n",
        "  trained_model = train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=50, device=device)\n",
        "\n",
        "    # eval the model\n",
        "  evaluate_model(trained_model, test_loader, device=device)\n",
        "\n",
        "    # save the model weights\n",
        "  torch.save(trained_model.state_dict(), 'lung_cancer_detection_model.pth')\n",
        "\n",
        "    # save the model in ONNX format\n",
        "  dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "  torch.onnx.export(trained_model, dummy_input, \"lung_cancer_detection_model.onnx\", input_names=['input'], output_names=['output'])\n",
        "\n",
        "  print(\"Training completed. Model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NTXf0ZZui80",
        "outputId": "f7246388-3c7e-4afb-9c2b-7e1b16caf12d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Number of training images: 613\n",
            "Number of validation images: 72\n",
            "Number of testing images: 315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.3373 Acc: 0.3409\n",
            "valid Loss: 1.3093 Acc: 0.3333\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 1.1875 Acc: 0.4812\n",
            "valid Loss: 1.1224 Acc: 0.4861\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 1.0307 Acc: 0.5383\n",
            "valid Loss: 0.9753 Acc: 0.5139\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.9385 Acc: 0.5710\n",
            "valid Loss: 0.9479 Acc: 0.5139\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.9361 Acc: 0.5579\n",
            "valid Loss: 0.9354 Acc: 0.5694\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.8883 Acc: 0.5840\n",
            "valid Loss: 0.9001 Acc: 0.5694\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.8642 Acc: 0.5905\n",
            "valid Loss: 0.8911 Acc: 0.5417\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.8090 Acc: 0.6427\n",
            "valid Loss: 0.8911 Acc: 0.6111\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.7707 Acc: 0.6721\n",
            "valid Loss: 0.8374 Acc: 0.6250\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.7411 Acc: 0.6884\n",
            "valid Loss: 0.8437 Acc: 0.6389\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.6976 Acc: 0.7080\n",
            "valid Loss: 0.7906 Acc: 0.6667\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.6498 Acc: 0.7406\n",
            "valid Loss: 0.7689 Acc: 0.6944\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.6072 Acc: 0.7504\n",
            "valid Loss: 0.7285 Acc: 0.6806\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.5567 Acc: 0.7765\n",
            "valid Loss: 0.7011 Acc: 0.6806\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.5174 Acc: 0.7830\n",
            "valid Loss: 0.7051 Acc: 0.7222\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.5148 Acc: 0.7912\n",
            "valid Loss: 0.7065 Acc: 0.7361\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.4672 Acc: 0.8271\n",
            "valid Loss: 0.6336 Acc: 0.7778\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.4645 Acc: 0.8189\n",
            "valid Loss: 0.6218 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.4157 Acc: 0.8450\n",
            "valid Loss: 0.6014 Acc: 0.7639\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.4395 Acc: 0.8303\n",
            "valid Loss: 0.5496 Acc: 0.7778\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.3911 Acc: 0.8483\n",
            "valid Loss: 0.5143 Acc: 0.7917\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.3471 Acc: 0.8711\n",
            "valid Loss: 0.5175 Acc: 0.7917\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.3732 Acc: 0.8597\n",
            "valid Loss: 0.5472 Acc: 0.7917\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.3144 Acc: 0.8825\n",
            "valid Loss: 0.5618 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.3533 Acc: 0.8613\n",
            "valid Loss: 0.5264 Acc: 0.8333\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.3521 Acc: 0.8483\n",
            "valid Loss: 0.5386 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.3877 Acc: 0.8499\n",
            "valid Loss: 0.5499 Acc: 0.8056\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.3018 Acc: 0.8858\n",
            "valid Loss: 0.5231 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.3106 Acc: 0.8777\n",
            "valid Loss: 0.5144 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.3138 Acc: 0.8646\n",
            "valid Loss: 0.4796 Acc: 0.8333\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.3168 Acc: 0.8793\n",
            "valid Loss: 0.5207 Acc: 0.8611\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2811 Acc: 0.8907\n",
            "valid Loss: 0.4896 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2758 Acc: 0.8858\n",
            "valid Loss: 0.5170 Acc: 0.8056\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2958 Acc: 0.8858\n",
            "valid Loss: 0.4890 Acc: 0.8472\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2740 Acc: 0.8907\n",
            "valid Loss: 0.5013 Acc: 0.8056\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2663 Acc: 0.9021\n",
            "valid Loss: 0.4735 Acc: 0.8611\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2500 Acc: 0.8972\n",
            "valid Loss: 0.5436 Acc: 0.8194\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.3073 Acc: 0.8923\n",
            "valid Loss: 0.4600 Acc: 0.8750\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2769 Acc: 0.8940\n",
            "valid Loss: 0.5052 Acc: 0.8472\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2362 Acc: 0.9038\n",
            "valid Loss: 0.4136 Acc: 0.8611\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2018 Acc: 0.9347\n",
            "valid Loss: 0.4231 Acc: 0.8333\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2267 Acc: 0.9184\n",
            "valid Loss: 0.4369 Acc: 0.8750\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2837 Acc: 0.8940\n",
            "valid Loss: 0.3961 Acc: 0.8750\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2350 Acc: 0.8989\n",
            "valid Loss: 0.4411 Acc: 0.8611\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2168 Acc: 0.9282\n",
            "valid Loss: 0.4236 Acc: 0.8472\n",
            "Learning rate: 1e-05\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2082 Acc: 0.9315\n",
            "valid Loss: 0.4029 Acc: 0.8750\n",
            "Learning rate: 5e-06\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.1763 Acc: 0.9462\n",
            "valid Loss: 0.4882 Acc: 0.8750\n",
            "Learning rate: 5e-06\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2349 Acc: 0.9103\n",
            "valid Loss: 0.4360 Acc: 0.8750\n",
            "Learning rate: 5e-06\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.1832 Acc: 0.9315\n",
            "valid Loss: 0.4472 Acc: 0.8750\n",
            "Learning rate: 5e-06\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2090 Acc: 0.9250\n",
            "valid Loss: 0.4237 Acc: 0.8750\n",
            "Learning rate: 5e-06\n",
            "\n",
            "Best val Acc: 0.8750\n",
            "Test Acc: 0.8508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-724529166.py:53: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(trained_model, dummy_input, \"lung_cancer_detection_model.onnx\", input_names=['input'], output_names=['output'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed. Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "#from architecture import ResNetLungCancer\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNetLungCancer(num_classes=4)\n",
        "model.load_state_dict(torch.load('lung_cancer_detection_model.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# image from local file\n",
        "image_path = \"Sets/Data/test/adenocarcinoma/000114.png\"\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "# preprocess the image\n",
        "input_tensor = preprocess(image).unsqueeze(0).to(device)  # add batch dimension and move to device\n",
        "\n",
        "# get model predictions\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "\n",
        "predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "class_names = ['Adenocarcinoma', 'Large Cell Carcinoma', 'Normal', 'Squamous Cell Carcinoma']\n",
        "\n",
        "print(f\"Predicted class: {class_names[predicted_class]}\")"
      ],
      "metadata": {
        "id": "wtV_JhnLSFY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1672303a-324e-4b52-f188-f211c3937fb3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Adenocarcinoma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "#from architecture import ResNetLungCancer\n",
        "import gradio as gr\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNetLungCancer(num_classes=4)\n",
        "model.load_state_dict(torch.load('lung_cancer_detection_model.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class_names = ['Adenocarcinoma', 'Large Cell Carcinoma', 'Normal', 'Squamous Cell Carcinoma']\n",
        "\n",
        "def predict(image):\n",
        "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "\n",
        "    predicted_class = torch.argmax(output, dim=1).item()\n",
        "    return class_names[predicted_class]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=gr.Label(num_top_classes=1),\n",
        "    examples=[\n",
        "        [\"Sets/Data/test/large.cell.carcinoma/000108.png\"],\n",
        "        [\"Sets/Data/test/normal/7 - Copy (3).png\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "BB4Vc6Az2AHQ",
        "outputId": "7b8767ae-2ce5-4ef9-8895-e35b1fd2f40b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ee4a768f64764a0b33.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee4a768f64764a0b33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}